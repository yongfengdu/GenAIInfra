# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

# Default values for vllm.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image:
  repository: vllm
# repository: opea/vllm
  tag: "openvino"

VLLM_CPU_KVCACHE_SPACE: "40"

# extraCmdArgs: ["--enforce-eager","--tensor-parallel-size","1","--block-size","128","--max-num-seqs","256","--max-seq_len-to-capture","2048"]
# Workaround for current OPENVINO image with start command /bin/bash, remember to modify the --model according to LLM_MODEL_ID
extraCmdArgs: ["/bin/bash","-c","python3 -m vllm.entrypoints.openai.api_server --enforce-eager --model Intel/neural-chat-7b-v3-3 --host 0.0.0.0 --port 2080 --download-dir /data"]
