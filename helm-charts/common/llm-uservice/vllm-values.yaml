# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

# Default values for llm-uservice.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

vLLM_ENDPOINT: ""
LLM_MODEL_ID: Intel/neural-chat-7b-v3-3
image:
  repository: opea/llm-vllm
  tag: "latest"

vllm:
  enabled: true
  LLM_MODEL_ID: Intel/neural-chat-7b-v3-3
  image:
    repository: vllm
    tag: "openvino"
  VLLM_CPU_KVCACHE_SPACE: "40"
  # extraCmdArgs: ["--enforce-eager","--tensor-parallel-size","1","--block-size","128","--max-num-seqs","256","--max-seq_len-to-capture","2048"]
  # Workaround for current OPENVINO image with start command /bin/bash
  extraCmdArgs: ["/bin/bash","-c","python3 -m vllm.entrypoints.openai.api_server --enforce-eager --model Intel/neural-chat-7b-v3-3 --host 0.0.0.0 --port 2080 --download-dir /data"]
